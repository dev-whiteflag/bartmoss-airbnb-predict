{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684d88d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:50:59.560195100Z",
     "start_time": "2023-10-09T23:50:59.553665400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2308e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:51:07.434194200Z",
     "start_time": "2023-10-09T23:51:07.426643600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Altere o diretório atual para o diretório onde o arquivo está localizado\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "# caminho_completo = \"/Users/odair/Downloads/Arquivos Airbnb/total_data.csv\"\n",
    "\n",
    "# Altere o diretório atual para o diretório onde o arquivo está localizado\n",
    "# os.chdir(os.path.dirname(caminho_completo))\n",
    "\n",
    "# df_Airbnb = pd.read_csv(caminho_completo)\n",
    "\n",
    "#os.chdir(\"D:\\\\Airbnb\")\n",
    "\n",
    "#df_Airbnb = pd.read_csv(\"total_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as colunas com valores NaN e a quantidade de registros NaN\n",
    "quantidade_nan_por_coluna = df_Airbnb.isna().sum()\n",
    "\n",
    "print(\"Colunas com valores NaN e suas quantidades:\")\n",
    "print(quantidade_nan_por_coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para determinar as estações do ano\n",
    "def estacao_do_ano(mes):\n",
    "    if 3 <= mes <= 5:\n",
    "        return 1 #'Primavera'\n",
    "    elif 6 <= mes <= 8:\n",
    "        return 2 #'Verão'\n",
    "    elif 9 <= mes <= 11:\n",
    "        return 3 #'Outono'\n",
    "    else:\n",
    "        return 4 #'Inverno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'data_string' para o tipo de dado de data\n",
    "df_Airbnb['last_scraped'] = pd.to_datetime(df_Airbnb['last_scraped'], format='%Y-%m-%d', errors='coerce')\n",
    "df_Airbnb['Data'] = df_Airbnb['last_scraped']\n",
    "df_Airbnb.set_index('Data', inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Normalizando os dados\n",
    "# Criar um codigo numerico para os campos texto\n",
    "df_Airbnb['neighbourhood_cleansed_encoded'] = label_encoder.fit_transform(df_Airbnb['neighbourhood_cleansed'])\n",
    "df_Airbnb['property_type_encoded'] = label_encoder.fit_transform(df_Airbnb['property_type'])\n",
    "df_Airbnb['room_type_encoded'] = label_encoder.fit_transform(df_Airbnb['room_type'])\n",
    "\n",
    "# Converter as colunas para um campo numerico\n",
    "df_Airbnb['id'] = pd.to_numeric(df_Airbnb['id'], errors='coerce', downcast='integer')\n",
    "df_Airbnb['host_id'] = pd.to_numeric(df_Airbnb['host_id'], errors='coerce', downcast='integer')\n",
    "df_Airbnb['accommodates'] = pd.to_numeric(df_Airbnb['accommodates'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Remova o símbolo de dólar ($) e outros caracteres não numéricos da coluna 'price'\n",
    "df_Airbnb['price'] = df_Airbnb['price'].str.replace('[\\$,]', '', regex=True)\n",
    "df_Airbnb['price'] = df_Airbnb['price'].astype(float)\n",
    "\n",
    "# Criando novas variáveis\n",
    "df_Airbnb['data_int'] = df_Airbnb['last_scraped'].dt.strftime('%Y%m%d').fillna(0).astype(int)\n",
    "df_Airbnb['media_price'] = df_Airbnb.groupby('neighbourhood_cleansed_encoded')['price'].transform('mean')\n",
    "df_Airbnb['mediana_price'] = df_Airbnb.groupby('neighbourhood_cleansed_encoded')['price'].transform('median')\n",
    "df_Airbnb['desvio_padrao_price'] = df_Airbnb.groupby('neighbourhood_cleansed_encoded')['price'].transform('std')\n",
    "df_Airbnb['maximo_price'] = df_Airbnb.groupby('neighbourhood_cleansed_encoded')['price'].transform('max')\n",
    "df_Airbnb['minimo_price'] = df_Airbnb.groupby('neighbourhood_cleansed_encoded')['price'].transform('min')\n",
    "\n",
    "df_Airbnb['growth_data_int'] = df_Airbnb['data_int'].pct_change()\n",
    "df_Airbnb['growth_media_price'] = df_Airbnb['media_price'].pct_change()\n",
    "df_Airbnb['price_quartiles'] = pd.qcut(df_Airbnb['price'], q=4, labels=False)\n",
    "\n",
    "df_Airbnb['mes'] = df_Airbnb['last_scraped'].dt.month\n",
    "df_Airbnb['estacao'] = df_Airbnb['mes'].apply(estacao_do_ano)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_Airbnb = pd.get_dummies(df_Airbnb, columns=['amenities'], prefix=['amenity'])\n",
    "\n",
    "# Gerar DF contendo codigo e descricao \n",
    "df_neighbourhood = df_Airbnb[[\"neighbourhood_cleansed_encoded\", \"neighbourhood_cleansed\"]]\n",
    "\n",
    "df_property = df_Airbnb[[\"property_type_encoded\", \"property_type\"]]\n",
    "\n",
    "df_room_type = df_Airbnb[[\"room_type_encoded\", \"room_type\"]]\n",
    "\n",
    "df_neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2840379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz uma cópia do df_Airbnb\n",
    "df = df_Airbnb.copy()\n",
    "\n",
    "\n",
    "# Cria um novo df com as colunas desejadas\n",
    "#df = df[[\"last_scraped\",\"neighbourhood_cleansed_encoded\", \"property_type_encoded\",\"room_type_encoded\",\"accommodates\",\n",
    "#         \"bathrooms\",\"bedrooms\",\"beds\",\"mes\",\"estacao\",\"data_int\",\"media_price\",\"mediana_price\",\"desvio_padrao_price\",\n",
    "#         \"maximo_price\",\"minimo_price\",\"growth_media_price\",\"price_quartiles\", \"price\"]]\n",
    "df = df[[\"last_scraped\",\"neighbourhood_cleansed_encoded\", \"property_type_encoded\",\"room_type_encoded\",\"accommodates\",\n",
    "         \"bathrooms\",\"bedrooms\",\"beds\",\"data_int\",\"media_price\",\"mediana_price\",\"desvio_padrao_price\",\n",
    "         \"maximo_price\",\"minimo_price\",\"growth_media_price\",\"price_quartiles\",\"mes\",\"estacao\", \"price\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantidade_nan_por_coluna = df.isna().sum()\n",
    "\n",
    "# Imprima as colunas com valores NaN e a quantidade de registros NaN\n",
    "print(\"Colunas com valores NaN e suas quantidades:\")\n",
    "print(quantidade_nan_por_coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apagar os registros com NAN\n",
    "df = df.dropna()\n",
    "\n",
    "# Separando os dados entre treinamento e teste\n",
    "Linhas = len(df)\n",
    "start_train = 0\n",
    "end_train = int(0.7 * Linhas)\n",
    "start_val = end_train + 1\n",
    "end_val = Linhas - 1\n",
    "\n",
    "print(\"Linhas Treinamento.: \", end_train)\n",
    "print(\"Linhas Teste.......: \", Linhas - end_train)\n",
    "print(\"Linhas Total.......: \", Linhas)\n",
    "\n",
    "df_train = df.iloc[start_train:end_train+1]\n",
    "df_val = df.iloc[start_val:end_val+1]\n",
    "\n",
    "\n",
    "#X = df_train.iloc[:, df_train.columns.get_loc(\"id\"):df_train.columns.get_loc(\"estacao\")+1]\n",
    "#y = df_train[\"price\"]\n",
    "\n",
    "#X_val = df_val.iloc[:, df_val.columns.get_loc(\"id\"):df_val.columns.get_loc(\"estacao\")+1]\n",
    "#y_val = df_val[\"price\"]\n",
    "\n",
    "X_train = df_train.iloc[:, df_train.columns.get_loc(\"neighbourhood_cleansed_encoded\"):df_train.columns.get_loc(\"estacao\")+1]\n",
    "y_train = df_train[\"price\"]\n",
    "\n",
    "X_test = df_val.iloc[:, df_val.columns.get_loc(\"neighbourhood_cleansed_encoded\"):df_val.columns.get_loc(\"estacao\")+1]\n",
    "y_test = df_val[\"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializando os 2 modelos\n",
    "model1 =  DecisionTreeClassifier(criterion = \"entropy\"\n",
    "                                     , max_depth = 80\n",
    "                                     , min_samples_leaf = 400\n",
    "                                     , min_samples_split = 9\n",
    "                                     , max_leaf_nodes = 850)\n",
    "model2 = LinearRegression()\n",
    "\n",
    "model3 =  DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "\n",
    "model5 =  RandomForestRegressor(n_estimators=100, random_state=42)  \n",
    "\n",
    "# Treinamento\n",
    "progress_bar = tqdm(total=15, position=0, leave=True, desc=\"Treinamento do Modelo\")\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "#model4.fit(X_train, y_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "model5.fit(X_train, y_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "# Predição na base de treinamento\n",
    "fit_train1 = model1.predict(X_train)\n",
    "progress_bar.update(1)\n",
    "fit_train2 = model2.predict(X_train)\n",
    "progress_bar.update(1)\n",
    "fit_train3 = model3.predict(X_train)\n",
    "progress_bar.update(1)\n",
    "#fit_train4 = model4.predict(X_train)\n",
    "\n",
    "\n",
    "progress_bar.update(1)\n",
    "fit_train5 = model5.predict(X_train)\n",
    "progress_bar.update(1)\n",
    "\n",
    "# Predicao na base de teste\n",
    "fit_test1 = model1.predict(X_test)\n",
    "progress_bar.update(1)\n",
    "fit_test2 = model2.predict(X_test)\n",
    "progress_bar.update(1)\n",
    "fit_test3 = model3.predict(X_test)\n",
    "progress_bar.update(1)\n",
    "#fit_test4 = model4.predict(X_test)\n",
    "\n",
    "progress_bar.update(1)\n",
    "fit_test5 = model5.predict(X_test)\n",
    "progress_bar.update(1)\n",
    "\n",
    "# Feche a barra de progresso quando estiver completa\n",
    "progress_bar.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a acurária do modelo\n",
    "# Como o alvo é um campo float (price), vamos calcular a acurácia manualmente.\n",
    "# As IA's tem funções para calculo de mse, msa, etc... para alvos binários\n",
    "def Acuracia(_df1,_df2,_modelo):\n",
    "    df_acuracia = pd.DataFrame(_df1)\n",
    "    df_acuracia[\"Data\"] = _df2.index\n",
    "    df_acuracia.rename(columns={0: 'Alvo'}, inplace=True)\n",
    "    df_acuracia.set_index('Data', inplace=True)\n",
    "    \n",
    "    df_result = pd.concat([_df2, df_acuracia], axis=1)\n",
    "    df_result[\"Acertou\"] = np.where((df_result['Alvo'] >= (df_result['price'] * 0.98) ) & \n",
    "                                    (df_result['Alvo'] <= (df_result['price'] * 1.02)  ), 1, 0)   \n",
    "    print(f\"{_modelo}..: {df_result['Acertou'].sum() / df_result['Acertou'].count() * 100:.2f}%, {df_result['Acertou'].sum()} / {df_result['Acertou'].count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[start_train:end_train+1]\n",
    "df_test = df.iloc[start_val:end_val+1]\n",
    "\n",
    "\n",
    "Acuracia(fit_train1,df_train,\"Base de Treinamento, modelo 1\")\n",
    "Acuracia(fit_train2,df_train,\"Base de Treinamento, modelo 2\")\n",
    "Acuracia(fit_train3,df_train,\"Base de Treinamento, modelo 3\")\n",
    "#Acuracia(fit_train4,df_train,\"Base de Treinamento, modelo 4\")\n",
    "Acuracia(fit_train5,df_train,\"Base de Treinamento, modelo 5\")\n",
    "print(\"=====================\")\n",
    "Acuracia(fit_test1,df_test,\"Base de Teste, modelo 1\")\n",
    "Acuracia(fit_test2,df_test,\"Base de Teste, modelo 2\")\n",
    "Acuracia(fit_test3,df_test,\"Base de Teste, modelo 3\")\n",
    "#Acuracia(fit_test4,df_test,\"Base de Teste, modelo 4\")\n",
    "Acuracia(fit_test5,df_test,\"Base de Teste, modelo 4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd56bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71626545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Modelo 1 apresenta a melhor acuracia\n",
    "caminho_completo = \"/Users/odair/Downloads/Arquivos Airbnb/Modelo_Airbnb.pkl\"\n",
    "\n",
    "pickle.dump(model1,open(caminho_completo, 'wb'))\n",
    "\n",
    "# Salvar modelo em windows\n",
    "#pickle.dump(model4,open('c:\\\\Users\\\\odair\\\\Python-MT5\\\\Modelo_Airbnb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o modelo para predicao\n",
    "\n",
    "meu_arquivo = open('/Users/odair/Downloads/Arquivos Airbnb/Modelo_Airbnb.pkl',  'rb')\n",
    "modelo = pickle.load(meu_arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_neighbourhood(nome):\n",
    "    id = df_neighbourhood[df_neighbourhood['neighbourhood_cleansed'] == nome]['neighbourhood_cleansed_encoded'].values[0]\n",
    "    return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbdb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_property_type(nome):\n",
    "    id = df_property[df_property['property_type'] == nome]['property_type_encoded'].values[0]\n",
    "    return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_room_type(nome):\n",
    "    id = df_room_type[df_room_type['room_type'] == nome]['room_type_encoded'].values[0]\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a previsao de precos\n",
    "\n",
    "neighbourhood = busca_neighbourhood(\"Copacabana\")\n",
    "property_type = busca_property_type(\"Condominium\")\n",
    "room_type = busca_room_type(\"Entire home/apt\")\n",
    "\n",
    "accommodates =5\n",
    "bathrooms =1 \n",
    "bedrooms =2\n",
    "beds=2\n",
    "mes = 8\n",
    "estacao = estacao_do_ano(mes)\n",
    "\n",
    "#print(neighbourhood,property_type,room_type, estacao)\n",
    "\n",
    "parametros = [neighbourhood, property_type, room_type, accommodates, bedrooms, bathrooms, beds, mes, estacao]\n",
    "\n",
    "# linha que faz a predição do modelo\n",
    "predict = modelo.predict([parametros])[0]\n",
    "print(f\"O preço da diária é: R$ {predict:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_Airbnb[df_Airbnb[\"neighbourhood_cleansed\"] == \"Copacabana\"]\n",
    "\n",
    "\n",
    "df4 = df4[[\"neighbourhood_cleansed\", \"property_type\", \"room_type\", \"price\"]]\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315aea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avalie o desempenho do modelo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_train)\n",
    "print(f\"Erro médio quadrático (KNN): {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddccaae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
